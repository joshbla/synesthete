project:
  name: "synesthete"
  version: "0.1.0"

data:
  train_dir: "data/train"
  num_samples: 100 # Scaled up
  sample_rate: 16000
  duration: 3.0
  height: 256
  width: 256
  fps: 30

model:
  frame_size: [256, 256]
  # 3.0 seconds * 30 fps = 90 frames
  num_frames: 90
  latent_dim: 256
  d_model: 512
  
train:
  output_dir: "models"
  epochs: 40
  batch_size: 32
  learning_rate: 0.0001
  save_name: "model_latest.pth"
  samples_per_epoch: 200 # Scaled up
  
vae:
  epochs: 20
  samples_per_epoch: 200 # Scaled up
  learning_rate: 0.0001
  batch_size: 64
  kld_weight: 0.1

diffusion:
  epochs: 40
  samples_per_epoch: 200 # Scaled up
  learning_rate: 0.0001
  batch_size: 32
  timesteps: 50
  # Phase 2 factorization (continuous style latent)
  style_dim: 64
  p_style_drop: 0.2
  # Phase 1 conditioning (frame-aligned audio feature timeline)
  # Each target frame is conditioned on its aligned audio feature vector, optionally
  # with a small neighbor context window (audio_feature_context).
  audio_feature_n_fft: 512
  audio_feature_num_bands: 8
  audio_feature_context: 0
  frames_per_clip: 10

tracker:
  enabled: true
  entity: null # Set this if using a team, otherwise defaults to user
  log_videos: false # Disable video uploads to save data/storage


inference:
  output_video: "output_test.mp4"
  # Phase 2: style control at inference time.
  # - "random": sample a new style latent per run (default)
  # - "zero": disable style randomness (useful for smoke tests / audio-reactivity checks)
  style_mode: "random"
  # Optional integer seed for deterministic style sampling (null = no seeding).
  style_seed: null

# Phase 3 data diversity knobs (optional).
# These affect which procedural visualizers are sampled for synthetic training data.
visualizers:
  # Probability of using an augmented wrapper (smooth postprocess stack).
  aug_prob: 0.35
  # Probability of choosing an organic/painterly family vs geometric.
  organic_prob: 0.5
  # Probability of composing 2â€“3 primitives into a single clip.
  composite_prob: 0.25
